{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "17y8hJ3cYcDeSHi-I_4vdx8bPEmc67zAp",
      "authorship_tag": "ABX9TyNYWtdIvWhLpJLheYcF76Ov",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vignesh312000/Classification---Health-Insurance-Cross-Sell-Prediction/blob/main/resolute.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from scipy.stats import zscore\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.decomposition import PCA\n"
      ],
      "metadata": {
        "id": "cm49VxPJIOFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SVNI4H3G1ob"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train and test data\n",
        "train_path = \"/content/drive/MyDrive/train.xlsx\"  # Update with your file path\n",
        "test_path = \"/content/drive/MyDrive/test.xlsx\"  # Update with your file path\n",
        "train_df = pd.read_excel(train_path)\n",
        "test_df = pd.read_excel(test_path)"
      ],
      "metadata": {
        "id": "ciBxUcy1IVf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=train_df.copy()"
      ],
      "metadata": {
        "id": "_qApC5JZj4pR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "H8dRw91oNhXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As far the Clustering technique is a Unsupervised learning so the target label is not needed so the process involves the dropping the variable \"target\"."
      ],
      "metadata": {
        "id": "z3MrklAKOIMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_targets = df['target'].nunique()\n",
        "\n",
        "print(\"Unique targets:\", unique_targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSuGPIMPjYzF",
        "outputId": "c370d7fc-ef7e-4062-8cea-274371d3f709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique targets: 160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=df.drop(['target'],axis=1)"
      ],
      "metadata": {
        "id": "RcdvWBnSNhKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.fillna(data.mean(), inplace=True)"
      ],
      "metadata": {
        "id": "yGEZKEn6wkV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "YQdUsmm2OGxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Outlier detection using z-score\n",
        "z_scores = zscore(data)\n",
        "abs_z_scores = np.abs(z_scores)\n",
        "filtered_entries = (abs_z_scores < 3).all(axis=1)\n"
      ],
      "metadata": {
        "id": "GBDJSREu06Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df = df[filtered_entries].copy()\n",
        "target = filtered_df['target']"
      ],
      "metadata": {
        "id": "JZFsm9uQ1HQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "sns.boxplot(data=filtered_df, orient=\"v\", palette=\"Set2\")\n",
        "plt.title(\"Box Plot of Features to Identify Outliers\")\n",
        "plt.ylabel(\"Feature Values\")\n",
        "plt.xlabel(\"Features\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G9lnQiAhzykq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task_1"
      ],
      "metadata": {
        "id": "zjT_OAZzzyPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(filtered_df.drop(['target'], axis=1))\n",
        "\n",
        "# Perform K-means clustering\n",
        "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
        "cluster_labels = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# Add cluster labels to the filtered DataFrame\n",
        "# Add cluster labels to the filtered DataFrame using .loc to avoid SettingWithCopyWarning\n",
        "filtered_df.loc[:, 'cluster'] = cluster_labels\n",
        "\n",
        "# Define a function to identify the cluster for a given data point\n",
        "def identify_cluster(data_point):\n",
        "    # Use the trained K-means model to predict the cluster for the given data point\n",
        "    cluster = kmeans.predict([data_point])[0]\n",
        "    # Find the centroid of the predicted cluster\n",
        "    centroid = kmeans.cluster_centers_[cluster]\n",
        "    # Calculate the distance between the data point and the centroid\n",
        "    distance = np.linalg.norm(data_point - centroid)\n",
        "    return cluster, distance\n",
        "\n"
      ],
      "metadata": {
        "id": "91_2_1PEzYHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"identify_cluster\" function takes a data point (data_point) as input, predicts the cluster using the trained K-means model, calculates the distance between the data point and the centroid of the predicted cluster, and returns the cluster label along with the distance."
      ],
      "metadata": {
        "id": "DFq5PzJdVA92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate clustering quality\n",
        "silhouette_avg = silhouette_score(X_scaled, cluster_labels)\n",
        "db_index = davies_bouldin_score(X_scaled, cluster_labels)\n",
        "ch_index = calinski_harabasz_score(X_scaled, cluster_labels)\n",
        "print(f\"Silhouette Score: {silhouette_avg}\")\n",
        "print(f\"Davies-Bouldin Index: {db_index}\")\n",
        "print(f\"Calinski-Harabasz Index: {ch_index}\")"
      ],
      "metadata": {
        "id": "zlQ97Cu9U_nH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Silhouette Score: Score of 0.218 suggests that there is a moderate degree of separation between the clusters, indicating that the clustering algorithm has produced reasonably distinct clusters.\n",
        "\n",
        "Davies-Bouldin Index: The value of approximately *1.505567* indicates a moderate level of separation between the clusters. Lower values suggest better clustering, indicating that the clusters are compact and well-separated.\n",
        "\n",
        "Calinski-Harabasz Index: The value of approximately 12394.1 is relatively high, indicating that the clusters are well-separated and dense. Higher values indicate better clustering, suggesting that the clusters are distinct from each other."
      ],
      "metadata": {
        "id": "rNfVkAd5fvsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Interpret the clusters and analyze the characteristics of each cluster\n",
        "cluster_analysis = filtered_df.groupby('cluster').mean()\n",
        "print(cluster_analysis)"
      ],
      "metadata": {
        "id": "fj_xPfAFa7gW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cluster 0:**\n",
        "- **Trend**: This cluster has relatively lower values across most features compared to the other clusters.\n",
        "- **Key Features**:\n",
        "  - Features T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18 have lower mean values compared to the other clusters.\n",
        "- **Observations**:\n",
        "  - The values in this cluster are consistently lower across all features.\n",
        "  - This cluster represents a group of data points with generally lower measurements across the features.\n",
        "\n",
        "**Cluster 1:**\n",
        "- **Trend**: This cluster has moderate values across most features.\n",
        "- **Key Features**:\n",
        "  - Features T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18 have moderate mean values compared to the other clusters.\n",
        "- **Observations**:\n",
        "  - The values in this cluster are neither extremely high nor low, indicating a moderate range of measurements across the features.\n",
        "  - This cluster represents a group of data points with moderate measurements across the features.\n",
        "\n",
        "**Cluster 2:**\n",
        "- **Trend**: This cluster has relatively higher values across most features compared to the other clusters.\n",
        "- **Key Features**:\n",
        "  - Features T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17, T18 have higher mean values compared to the other clusters.\n",
        "- **Observations**:\n",
        "  - The values in this cluster are consistently higher across all features.\n",
        "  - This cluster represents a group of data points with generally higher measurements across the features.\n",
        "\n",
        "These interpretations provide insights into the characteristics of each cluster based on the mean feature values. It helps in understanding the differences between the clusters and can be useful for further analysis or decision-making."
      ],
      "metadata": {
        "id": "BS9--wjkffzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize clusters using PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_labels, cmap='viridis', s=50, alpha=0.5, label='Data Points')\n",
        "centroids_pca = pca.transform(kmeans.cluster_centers_)\n",
        "plt.scatter(centroids_pca[:, 0], centroids_pca[:, 1], marker='X', c='red', s=200, label='Centroids')\n",
        "plt.title('K-means Clustering Visualization')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3dbnUUgGfzSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross Validation for scores"
      ],
      "metadata": {
        "id": "wXnnjNQXkoXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_splits = 5\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "silhouette_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X_scaled):\n",
        "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
        "    kmeans = KMeans(n_clusters=3, n_init=10)  # Explicitly set n_init to suppress warning\n",
        "    kmeans.fit(X_train)\n",
        "    cluster_labels = kmeans.predict(X_test)\n",
        "    silhouette_avg = silhouette_score(X_test, cluster_labels)\n",
        "    silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "average_silhouette_score = np.mean(silhouette_scores)\n",
        "print(\"Average Silhouette Score:\", average_silhouette_score)"
      ],
      "metadata": {
        "id": "vvcLusj4knjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6TWj7mk7wowp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task_2"
      ],
      "metadata": {
        "id": "OVtwTNyFkGrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop 'target' column for training\n",
        "X_train = train_df.drop(['target'], axis=1)\n",
        "y_train = train_df['target']\n",
        "\n",
        "# Fill missing values with mean\n",
        "X_train.fillna(X_train.mean(), inplace=True)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)"
      ],
      "metadata": {
        "id": "Woi7UwP5kF14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train RandomForestClassifier\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "xD-yMaBakMRJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "ba9d3079-1720-479d-9087-6f02f7b83f9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data (assuming test data has the same features as train data)\n",
        "y_pred = clf.predict(X_train)\n",
        "\n",
        "# Calculate train accuracy\n",
        "train_accuracy = accuracy_score(y_train, y_pred)\n",
        "\n",
        "# Share target values for the test data (assuming test data has the same features as train data)\n",
        "test_predictions = clf.predict(test_df)\n",
        "\n",
        "print(\"Train Accuracy:\", train_accuracy)"
      ],
      "metadata": {
        "id": "_bxj54PJkNAy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8b0637c-6b21-4c02-debd-dd1e7fef4fd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9994286025250326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame with row numbers and corresponding predicted targets\n",
        "test_predictions_df = pd.DataFrame({\n",
        "    'Row Number': test_df.index + 1,  # Adding 1 to start row numbers from 1\n",
        "    'Target': test_predictions\n",
        "})\n",
        "\n",
        "# Print the DataFrame with test predictions\n",
        "print(\"Test Predictions:\")\n",
        "print(test_predictions_df.to_string(index=False))"
      ],
      "metadata": {
        "id": "tT5uscKnkM0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add predictions to the test DataFrame\n",
        "test_df['Prediction'] = test_predictions\n",
        "\n",
        "# Save the updated test DataFrame to an Excel file\n",
        "output_path = \"/content/drive/MyDrive/test_with_predictions.xlsx\"  # Update with your desired output path\n",
        "test_df.to_excel(output_path, index=False)\n",
        "\n",
        "print(\"Test predictions saved to:\", output_path)"
      ],
      "metadata": {
        "id": "dtYPTiAokTht",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b207ffc0-f305-4637-e0f5-2441c91d0eee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test predictions saved to: /content/drive/MyDrive/test_with_predictions.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model training"
      ],
      "metadata": {
        "id": "z6TQTQduvkBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n",
        "X_train, X_test, y_train, y_test = train_test_split(filtered_df.drop(['target'], axis=1), target, test_size=0.2, random_state=42)\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h65lb7buqCg",
        "outputId": "7b83da58-9643-4a25-e1f2-5282b1cc3b69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9866340902558206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gMrHX79UNYcN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Random Forest Classifier was chosen for its versatility, robustness, and ability to handle both classification and regression tasks effectively. Here are some reasons why this algorithm might have been selected:\n",
        "\n",
        "## High Accuracy:\n",
        "Random Forest Classifier tends to provide high accuracy on a wide range of datasets without much parameter tuning. It is an ensemble method that combines multiple decision trees, which helps in reducing overfitting and improving accuracy.\n",
        "\n",
        "##Robust to Overfitting:\n",
        " Random Forest Classifier mitigates the risk of overfitting by averaging multiple decision trees built on random subsets of the data and features. This makes it more robust compared to individual decision trees.\n",
        "\n",
        "##Handles Both Numerical and Categorical Features:\n",
        " Random Forest Classifier can handle both numerical and categorical features without the need for feature scaling or one-hot encoding. This makes it convenient when working with diverse datasets.\n",
        "\n",
        "##Implicit Feature Selection:\n",
        "Random Forest Classifier implicitly performs feature selection by considering subsets of features at each split. This can be beneficial when dealing with high-dimensional data or datasets with redundant features.\n",
        "\n",
        "Overall, the Random Forest Classifier is a popular choice for classification tasks due to its ease of use, robustness, and ability to provide high accuracy across various types of datasets. However, it's essential to consider the specific characteristics of your dataset and problem domain when choosing the most appropriate algorithm."
      ],
      "metadata": {
        "id": "HV49BhHLNWGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "print(\"Precision:\", precision)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "# Calculate F1-score\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7s9pph5nOa29",
        "outputId": "dc2c3955-495d-43c0-ce42-01da4641aea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9867266834732401\n",
            "Recall: 0.9866340902558206\n",
            "F1-score: 0.9865966336896794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The precision, recall, and F1-score are all very high, indicating excellent performance of the classifier on the test set:\n",
        "\n",
        "- Precision: 0.9879\n",
        "  Precision represents the ratio of correctly predicted positive observations to the total predicted positives. In this case, it indicates that 98.79% of the samples predicted as positive by the classifier are actually positive.\n",
        "\n",
        "- Recall: 0.9878\n",
        "  Recall, also known as sensitivity, measures the ratio of correctly predicted positive observations to all actual positives. It tells us that 98.78% of the actual positive samples were correctly identified by the classifier.\n",
        "\n",
        "- F1-score: 0.9878\n",
        "  The F1-score is the harmonic mean of precision and recall. It provides a balance between precision and recall. A high F1-score indicates that the classifier has both high precision and high recall.\n",
        "\n",
        "These high values suggest that the classifier is performing very well in terms of correctly predicting both positive and negative samples, demonstrating its effectiveness in classification tasks."
      ],
      "metadata": {
        "id": "OtSybb6pOktG"
      }
    }
  ]
}